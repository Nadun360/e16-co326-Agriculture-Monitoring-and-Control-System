# -*- coding: utf-8 -*-
"""notebookea18ac6fb3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uaNHWeNSn1Cp5Wd3eCFqYEKdiEAh_Xz2

# SoilPH Prediction

This project introduces common techniques to manipulate time series and make predictions.

The data is a sample from the historical (https://www.kaggle.com/atulanandjha/soil_pherature-readings-iot-devices).
There are readings of 11 months
"""



"""## Clean data """

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error
from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error

from scipy.optimize import minimize
import statsmodels.tsa.api as smt
import statsmodels.api as sm

from tqdm import tqdm_notebook

from itertools import product

def mean_absolute_percentage_error(y_true, y_pred):
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

import warnings
warnings.filterwarnings('ignore')

import time
from datetime import datetime
from datetime import timedelta

# %matplotlib inline

lag_value=18

DATAPATH = 'test.csv'

data = pd.read_csv(DATAPATH)
data.head(10)

# data.shape()

# data.dtypes

# data.head(39)

# data.shape

# data.head()

drop_cols = ['name']
data.drop(drop_cols, axis=1, inplace=True)

# data.head()

"""## extract PH values"""

new_ph=[]
for i in data['soil_ph']:
    new_ph.append(float(i[8:12]))
data['soil_ph']=new_ph

data.head()

# print(data['time'][0])
# import time; 
# n=data['time'][0]
# print(n)
# n=n//1000000000
# print(n)
# print(type(n))
# time.strftime("%Y %b %d %H:%M:%S", time.localtime(n))

new_time=[]
for i in data['time']:
    i=i//1000000000
    date_str1=time.strftime("%Y %b %d %H:%M:%S", time.localtime(i))
    date_dt1 = datetime.strptime(date_str1, "%Y %b %d %H:%M:%S")
    new_time.append(date_dt1)
data['time']=new_time



data.head()

data.head(39)

"""## Exploratory data analysis (EDA)"""

plt.figure(figsize=(27, 8))
plt.plot(data.soil_ph)
plt.title('Soil PH Value (PH)')
plt.ylabel('Soil PH Value (PH)')
# plt.ylim(10,60)
plt.xlabel('Date & Time')
plt.grid(False)
#plt.show()

"""### Moving average"""

def plot_moving_average(series, window, plot_intervals=False, scale=1.96):

    rolling_mean = series.rolling(window=window).mean()
    
    plt.figure(figsize=(17,8))
    plt.title('Moving average\n window size = {}'.format(window))
    plt.plot(rolling_mean, 'g', label='Rolling mean trend')
    
    #Plot confidence intervals for smoothed values
    if plot_intervals:
        mae = mean_absolute_error(series[window:], rolling_mean[window:])
        deviation = np.std(series[window:] - rolling_mean[window:])
        lower_bound = rolling_mean - (mae + scale * deviation)
        upper_bound = rolling_mean + (mae + scale * deviation)
        plt.plot(upper_bound, 'r--', label='Upper bound / Lower bound')
        plt.plot(lower_bound, 'r--')
            
    plt.plot(series[window:], label='Actual values')
    plt.legend(loc='best')
    plt.grid(True)

#Smooth by the previous 5 days (by week)
plot_moving_average(data.soil_ph, 5)

#Smooth by the previous month (30 days)
plot_moving_average(data.soil_ph, 30)

#Smooth by previous quarter (90 days)
# plot_moving_average(data.soil_ph, 90, plot_intervals=True)

"""### Exponential smoothing"""

def exponential_smoothing(series, alpha):

    result = [series[0]] # first value is same as series
    for n in range(1, len(series)):
        result.append(alpha * series[n] + (1 - alpha) * result[n-1])
    return result

def plot_exponential_smoothing(series, alphas):
 
    plt.figure(figsize=(17, 8))
    for alpha in alphas:
        plt.plot(exponential_smoothing(series, alpha), label="Alpha {}".format(alpha))
    plt.plot(series.values, "c", label = "Actual")
    plt.legend(loc="best")
    plt.axis('tight')
    plt.title("Exponential Smoothing")
    plt.grid(True);

plot_exponential_smoothing(data.soil_ph, [0.05, 0.3])

"""### Double exponential smoothing """

def double_exponential_smoothing(series, alpha, beta):

    result = [series[0]]
    for n in range(1, len(series)+1):
        if n == 1:
            level, trend = series[0], series[1] - series[0]
        if n >= len(series): # forecasting
            value = result[-1]
        else:
            value = series[n]
        last_level, level = level, alpha * value + (1 - alpha) * (level + trend)
        trend = beta * (level - last_level) + (1 - beta) * trend
        result.append(level + trend)
    return result

def plot_double_exponential_smoothing(series, alphas, betas):
     
    plt.figure(figsize=(17, 8))
    for alpha in alphas:
        for beta in betas:
            plt.plot(double_exponential_smoothing(series, alpha, beta), label="Alpha {}, beta {}".format(alpha, beta))
    plt.plot(series.values, label = "Actual")
    plt.legend(loc="best")
    plt.axis('tight')
    plt.title("Double Exponential Smoothing")
    plt.grid(True)

plot_double_exponential_smoothing(data.soil_ph, alphas=[0.9, 0.02], betas=[0.9, 0.02])

lag_value=18

"""## Stationarity """

def tsplot(y, lags=None, figsize=(12, 7), syle='bmh'):
    
    if not isinstance(y, pd.Series):
        y = pd.Series(y)
        
    with plt.style.context(style='bmh'):
        fig = plt.figure(figsize=figsize)
        layout = (2,2)
        ts_ax = plt.subplot2grid(layout, (0,0), colspan=2)
        acf_ax = plt.subplot2grid(layout, (1,0))
        pacf_ax = plt.subplot2grid(layout, (1,1))
        
        y.plot(ax=ts_ax)
        p_value = sm.tsa.stattools.adfuller(y)[1]
        ts_ax.set_title('Time Series Analysis Plots\n Dickey-Fuller: p={0:.5f}'.format(p_value))
        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)
        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)
        plt.tight_layout()
        
tsplot(data.soil_ph, lags=lag_value)

data_diff = data.soil_ph - data.soil_ph.shift(1)

tsplot(data_diff[1:], lags=lag_value)

"""## SARIMA"""

#Set initial values and some bounds
ps = range(0, 3)
d = 1
qs = range(0, 3)
Ps = range(0, 3)
D = 1
Qs = range(0, 3)
s = 3

#Create a list with all possible combinations of parameters
parameters = product(ps, qs, Ps, Qs)
parameters_list = list(parameters)
len(parameters_list)

def optimize_SARIMA(parameters_list, d, D, s):
    """
        Return dataframe with parameters and corresponding AIC
        
        parameters_list - list with (p, q, P, Q) tuples
        d - integration order
        D - seasonal integration order
        s - length of season
    """
    
    results = []
    best_aic = float('inf')
    
    for param in tqdm_notebook(parameters_list):
        try: model = sm.tsa.statespace.SARIMAX(data.soil_ph, order=(param[0], d, param[1]),
                                               seasonal_order=(param[2], D, param[3], s)).fit(disp=-1)
        except:
            continue
            
        aic = model.aic
        
        #Save best model, AIC and parameters
        if aic < best_aic:
            best_model = model
            best_aic = aic
            best_param = param
        results.append([param, model.aic])
        
    result_table = pd.DataFrame(results)
#     print(result_table)
    result_table.columns = ['parameters', 'aic']
    #Sort in ascending order, lower AIC is better
    result_table = result_table.sort_values(by='aic', ascending=True).reset_index(drop=True)
    
    return result_table

result_table = optimize_SARIMA(parameters_list, d, D, s)

#Set parameters that give the lowest AIC (Akaike Information Criteria)

p, q, P, Q = result_table.parameters[0]

best_model = sm.tsa.statespace.SARIMAX(data.soil_ph, order=(p, d, q),
                                       seasonal_order=(P, D, Q, s)).fit(disp=-1)

#print(best_model.summary())

def plot_SARIMA(series, model, n_steps):
    """
        Plot model vs predicted values
        
        series - dataset with time series
        model - fitted SARIMA model
        n_steps - number of steps to predict in the future
    """
    
    data = series.copy().rename(columns = {'soil_ph': 'actual'})
    data['arima_model'] = model.fittedvalues
    #Make a shift on s+d steps, because these values were unobserved by the model due to the differentiating
    data['arima_model'][:s+d] = np.NaN
    
    #Forecast on n_steps forward
    forecast = model.predict(start=data.shape[0], end=data.shape[0] + n_steps)
    forecast = data.arima_model.append(forecast)
    #Calculate error
    error = mean_absolute_percentage_error(data['actual'][s+d:], data['arima_model'][s+d:])
    
    plt.figure(figsize=(17, 8))
    plt.title('Mean Absolute Percentage Error: {0:.2f}%'.format(error))
    plt.plot(forecast, color='r', label='model')
    plt.axvspan(data.index[-1], forecast.index[-1],alpha=0.5, color='lightgrey')
    plt.plot(data, label='actual')
    plt.legend()
    plt.grid(True);
    
prediction_days = 180
# plot_SARIMA(data, best_model, 5)
# print(data.soil_ph.shape[0])
# date_dt1 += timedelta(seconds=1)
# print(best_model.predict(start=data.soil_ph.shape[0], end=data.soil_ph.shape[0] + prediction_days))
pred_start_num=data.soil_ph.shape[0]
days=[]
soil_predictions=[]
for i in range(prediction_days):
    date_dt1 += timedelta(seconds=1)
    pred=best_model.predict(pred_start_num)
#     print(float(pred.to_string(index=False)))
#     print(date_dt1)
    days.append(str(date_dt1))
    soil_predictions.append(pred.to_string(index=False))
    pred_start_num+=1
#print(days)
#print(soil_predictions)
# print(mean_absolute_percentage_error(data.soil_ph[s+d:], best_model.fittedvalues[s+d:]))


import paho.mqtt.client as mqtt_client
import random
import json
import time

broker = 'broker.hivemq.com'
port = 1883
topic = "CO326/2021/Cloud/soil_ph_predictions"
client_id = f'co326-mqtt-{random.randint(0, 1000)}'

publish_period = 0.1  # in seconds

def connect_mqtt():
    def on_connect(client, userdata, flags, rc):
        if rc == 0:
            print("Connected to MQTT Broker!")
        else:
            print("Failed to connect, return code %d\n", rc)

    def on_disconnect(client, userdata, rc):
        print("Disconnected, return code %d\n", rc)
        global isConnected
        isConnected = False

    client = mqtt_client.Client(client_id)
    client.on_connect = on_connect
    client.on_disconnect = on_disconnect
    client.connect(broker, port)
    client.loop_start()
    return client


def publish(client, msg):
    result = client.publish(topic, msg, qos=2)
    status = result[0]
    if status == 0:
        print(f"Send `{msg}` to topic `{topic}`")
    else:
        print(f"Failed to send message to topic {topic}")


if __name__ == '__main__':
    client = connect_mqtt()
    for i in range(prediction_days):
        publish(client, json.dumps({ "date_time": str(days[i]),"soil_ph": str(soil_predictions[i]) }))
        time.sleep(publish_period)

# comparison = pd.DataFrame({'actual': [18.93, 19.23, 19.08, 19.17, 19.11, 19.12],
#                           'predicted': [18.96, 18.97, 18.96, 18.92, 18.94, 18.92]}, 
#                           index = pd.date_range(start='2018-06-05', periods=6,))

# comparison.head()

# plt.figure(figsize=(17, 8))
# plt.plot(comparison.actual)
# plt.plot(comparison.predicted)
# plt.title('Predicted soil_ph')
# plt.ylabel('soil_ph (PH)')
# plt.xlabel('Day & Time')
# plt.legend(loc='best')
# plt.grid(False)
# plt.show()
